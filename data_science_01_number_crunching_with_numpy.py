# -*- coding: utf-8 -*-
"""Data Science 01 - Number Crunching with NumPy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qiS9ffES2xEIqOm0SwQ-cl9t-oz9xsrn
"""

!pip install -q numpy scipy

"""# Chapter 1: Number Crunching with NumPy [https://tinyurl.com/ybgptlcf]

Prachya Boonkwan

Email: prachya.boonkwan@nectec.or.th, kaamanita@gmail.com 

(C) January 2019

Slide presentation can be found here --> **[https://tinyurl.com/yxl68949](https://tinyurl.com/yxl68949)**.

## Header

This part is the header of the code. My favorite import alias for NumPy is `np`. This is quite useful for speed coding.
"""

#!/usr/bin/env python3
#-*- coding: utf-8 -*-

import numpy as np               # for tensor computation
import numpy.random as rnd       # for randomization
import numpy.linalg as la        # for linear algebra
import scipy.sparse as sp        # for sprase matrices

"""*TRICK:* You can partially type in a command and press `[TAB]` to complete it. In the following line, remove the comment sign `#`, then type in `np.arr` after the equal sign. Press `[TAB]` to see a dropdown list of available commands."""

# my_matrix =

"""-----

## 1. Vectors

### 0-Vector

- This is how we declare a vector.
- Let's begin with a 0-vector using the command `np.zeros`.
- For example, `np.zeros(3)` will create the vector $\left[ 
\begin{array}{ccc}
    0 & 0 & 0
\end{array} \right]$.
"""

vec1 = np.zeros(3)     # Change the number of elements for more fun.
print(vec1)

"""### 1-Vector

- This is how we declare a 1-vector with the command `np.ones`.
- For example, `np.ones(3)` will create the vector $\left[ 
\begin{array}{ccc}
    1 & 1 & 1
\end{array} \right]$.
"""

vec2 = np.ones(3)      # Change the number of elements for more fun.
print(vec2)

"""### Custom Vector

- We declare a custom vector with `np.array`. 
- Here is how we define the vector $
\left[ \begin{array}{ccc}
    1, 2, 3
\end{array} \right]
$.
"""

vec3 = np.array([1.0, 2.0, 3.0])    # Add more elements for more fun.
print(vec3)

"""### Size

- We can find the size of a vector with the property `shape`.
"""

print(vec3.shape)

"""### Randomized Vector

- There are two ways to generate a randomized vector: `rnd.randn` for a floating point vector and `rnd.randint` for an integer vector. 

- `rnd.randn(size)` generates a floating point vector of size `size`, whose element is a floating point number drawn from a normal distribution.
"""

vec4 = rnd.randn(3)
print(vec4)

"""- `rnd.randint(start, end, size)` generates an integer vector of size `size`, whose element is in the range from `start` (inclusive) to `end` (exclusive)."""

vec5 = rnd.randint(1, 10, 5)
print(vec5)

"""### Indexing

- We can refer to an element in a vector by indexing `[]`. Note that the index starts with 0.
"""

print(vec3[1])           # the second element

print(vec3[2])           # the third element

# print(vec3[20])          # This will cause an error message due to out-of-bounds indexing

"""### Element Setting

- We can also set the value of a vector's element by indexing `[]`.
- For example, let's set the second element of `vec3` to be 100.
"""

vec5 = np.array([1.0, 2.0, 3.0])

print(f'Before: vec5 = {vec5}')
vec5[1] = 100            # Set the second element to be 100.
print(f'After : vec5 = {vec5}')

"""### Dot Product

- We can compute the dot product of two vectors by the operator `@`. 
- For example, let's compute the dot product of `vec6` and `vec7`.
"""

vec6 = np.array([5, 6, 7, 8])
vec7 = np.array([9, 10, 11, 12])
dotval = vec6 @ vec7
print(dotval)

"""- We can also use the method `dot` of the first operand."""

dotval = vec6.dot(vec7)
print(dotval)

"""### Vector Norm

- We can also compute the norm (i.e. size) of a vector $\left\| \mathbf{v} \right\|$ by the command `la.norm`.
- The command computes Frobenius norm, where:
$$
\begin{eqnarray}
    \left\| \mathbf{v} \right\| & = & \mathrm{Frobenius}(\mathbf{v}) \\
    & = & \sqrt{ \sum_{i = 1}^N v_i^2 } \\
    & = & \sqrt{ v_1^2 + v_2^2 + v_3^2 + \ldots + v_N^2 }
\end{eqnarray}
$$
"""

vecnorm = la.norm(vec6)
print(vecnorm)

"""-----

## Exercises 1

### Question 1.1

Compute $\mathbf{a} + 4 \mathbf{b} - 3 \mathbf{c}$, where
$$
\begin{eqnarray}
    \mathbf{a} & = & \left[  \begin{array}{ccc}
        1 & 1 & 1
    \end{array} \right] \\
    \mathbf{b} & = & \left[  \begin{array}{ccc}
        4 & 5 & 6
    \end{array} \right] \\
    \mathbf{c} & = & \left[  \begin{array}{ccc}
        0 & 0 & 0
    \end{array} \right]
\end{eqnarray}
$$
"""

# vec_a = __________           # Fill in these blanks
# vec_b = __________
# vec_c = __________
# result = __________
# 
# print(f'result = {result}')

"""#### Solution"""

vec_a = np.ones(3)
vec_b = np.array([4, 5, 6])
vec_c = np.zeros(3)
result = vec_a + 4 * vec_b - 3 * vec_c

print(f'result = {result}')

"""### Question 1.2

Compute $10 \times \mathbf{a} \cdot \mathbf{b}$, where $\mathbf{a}$ and $\mathbf{b}$ are randomized vectors of size 10.
"""

# vec_a = __________           # Fill in these blanks
# vec_b = __________
# result = __________
# 
# print(f'result = {result}')

"""#### Solution"""

vec_a = rnd.randn(10)
vec_b = rnd.randn(10)
result = 10 * vec_a @ vec_b

print(f'result = {result}')

"""### Question 1.3

Create a vector of size 32 named `vec_nums`. Each even-indexed cell contains an even number from 0 to 30, ascendingly sorted. And each odd-indexed cell contains an odd number from 31 to 1, descendingly sorted. The result should look like this:

```python
[0, 31, 2, 29, 4, 27, ..., 26, 5, 28, 3, 30, 1]
```
"""

# vec_nums = np.zeros(32, dtype=np.int64)      # The datatype is 64-bit integer
# 
# # Loop over the index i and fill up the vector according to the index.
# for i in range(32):
#     __________
# 
# print(vec_nums)

"""##### Solution"""

vec_nums = np.zeros(32, dtype=np.int64)      # The datatype is 64-bit integer

# Loop over the index i and fill up the vector according to the index.
for i in range(32):
    if i % 2 == 0:
        vec_nums[i] = i
    else:
        vec_nums[i] = 32 - i

print(vec_nums)

"""### Question 1.4

Compute a unit vector of `vec_nums`.

$$
\begin{eqnarray}
    \mathrm{unit}(\mathbf{v}) & = & \frac{\mathbf{v}}{\left\| \mathbf{v} \right\|}
\end{eqnarray}
$$
"""

# unit_vecnums = __________          # Fill in this blank
# 
# print(unit_vecnums)

"""#### Solution"""

unit_vecnums = vec_nums / la.norm(vec_nums)

print(unit_vecnums)

"""-----
## 2. Matrices

### 0-Matrix

- This is how we declare a matrix.
- A 0-matrix can again be defined with `np.zeros`, but this time we identify the size of each dimension (a.k.a. the *shape*), too.
- For example, `np.zeros((3, 4))` will create the matrix

$$\left[ 
\begin{array}{cccc}
    0 & 0 & 0 & 0 \\
    0 & 0 & 0 & 0 \\
    0 & 0 & 0 & 0
\end{array} \right]_{3 \times 4}
$$
"""

mat1 = np.zeros((3, 4))     # Change the number of elements on any dimension.
print(mat1)

"""- The reason of putting an extra pair of parentheses over the shape is because the next parameter of all array creation functions is the data type `dtype`.
- This data type can be floating point `np.float`{16, 32, 64, 128}, integer `np.int`{8, 16, 32, 64}, and complex numbers `np.complex`.
- The default data type is `np.float64`.
"""

mat1 = np.zeros((3, 4), dtype=np.float64)      # each element is of the type 64-bit floating point
print(mat1)

"""### 1-Matrix

- We define a 1-matrix with `np.ones` in the same fashion. 
- For example, `np.ones((3, 4))` will create the matrix
$$\left[ 
\begin{array}{cccc}
    1 & 1 & 1 & 1 \\
    1 & 1 & 1 & 1 \\
    1 & 1 & 1 & 1
\end{array} \right]_{3 \times 4}
$$
"""

mat2 = np.ones((3, 4))      # Change the number of elements on any dimension.
print(mat2)

"""### Identity Matrix

- This is how you define an identity matrix with `np.eye`. 
- For example, `np.eye(3)` will create the 3-dimensional identity matrix
$$\left[ 
\begin{array}{ccc}
    1 & 0 & 0 \\
    0 & 1 & 0 \\
    0 & 0 & 1
\end{array} \right]_{3 \times 3}
$$
"""

mat3 = np.eye(3)       # Change the number of elements on any dimension.
print(mat3)

"""- We can also determine the number of columns if we desire a non-square matrix."""

mat3 = np.eye(3, 4)       # Change the number of elements on any dimension.
print(mat3)

"""### Randomized Matrix

- We define a randomized matrix with `rnd.randn` (floating point) and `rnd.randint` (integer).
"""

mat_rand = rnd.randn(3, 4)        # Change the number of elements on any dimension.
print(mat_rand)

mat_randint = rnd.randint(1, 10, (3, 4))
print(mat_randint)

"""### Custom Matrix

- A custom matrix can be defined with `np.array`. 
- Notice that a 2-dimensional matrix is just a list of lists.
- Here we define the matrix
$$
\left[ \begin{array}{ccc}
    1 & 2 & 3 \\
    4 & 5 & 6
\end{array} \right]_{2 \times 3}
$$
- Each row becomes a list. For example, the first row becomes `[1, 2, 3]`, and the second row, `[4, 5, 6]`.
"""

# Play with the elements, rows, or columns for more fun.
mat4 = np.array( [ [1, 2, 3],
                   [4, 5, 6] ] )
print(mat4)

"""### Shape

- We can also find the size of a matrix with the property `shape`.
"""

print(mat4.shape)

"""### Cell Indexing and Setting

- We can refer to a particular cell of a matrix by indexing `[]`.
"""

print(mat4[0,1])            # cell (1,2)

print(mat4[1,2])            # cell (2,3)

mat4 = np.array( [ [1, 2, 3],
                   [4, 5, 6] ] )

print(f'Before: mat4 =\n{mat4}')
mat4[1,2] = 100             # Set the value of cell (2,3) to be 100.
print(f'After : mat4 =\n{mat4}')

"""### Row Indexing

- We can index a row of a matrix by `[]`, too.
"""

mat5 = np.array( [ [1, 2, 3],
                   [4, 5, 6] ] )

print(f'row 1 of mat5 = {mat5[0]}')
print(f'row 2 of mat5 = {mat5[1]}')

"""### Row Setting

- Setting a row is as simple. For example, we can replace the first row of `mat5` by setting `mat5[0]` to be another vector.
"""

mat5 = np.array( [ [1, 2, 3],
                   [4, 5, 6] ] )

print(f'Before: mat5 =\n{mat5}')
mat5[0] = np.array([7, 8, 9])
print(f'After : mat5 =\n{mat5}')

"""### Column Indexing

- We can also get access to a column of a matrix by replacing the row index with `:`.
"""

mat6 = np.array( [ [1, 2, 3],
                   [4, 5, 6] ] )

print(f'column 1 of mat6 = {mat6[:, 0]}')
print(f'column 2 of mat6 = {mat6[:, 1]}')
print(f'column 3 of mat6 = {mat6[:, 2]}')

"""### Column Setting

- Setting a column can be as simple. For example, we can replace the first column of `mat6` by setting `mat6[:, 0]` to be another vector.
"""

mat6 = np.array( [ [1, 2, 3],
                   [4, 5, 6] ] )

print(f'Before: mat6 =\n{mat6}')
mat6[:, 0] = np.array([7, 8])
print(f'After : mat6 =\n{mat6}')

"""### Matrix stacking

- We can stack two matrices with the following commands:

  - `np.hstack` for horizontal stacking
  - `np.vstack` for vertical stacking
  -  `np.concatenate` for concatenation on a specified axis

- The last command is a generalization of the previous two. Note that these commands require a tuple of matrices to be stacked.

**Vertical stacking `np.vstack`**

$$
\begin{eqnarray}
    \left[ \begin{array}{ccc}
        1 & 2 & 3 \\
        4 & 5 & 6
    \end{array} \right]_{2 \times 3}
    \oplus_0
    \left[ \begin{array}{ccc}
        7 & 8 & 9 \\
        10 & 11 & 12
    \end{array} \right]_{2 \times 3}
    & = &
    \left[ \begin{array}{ccc}
        1 & 2 & 3 \\
        4 & 5 & 6 \\
        7 & 8 & 9 \\
        10 & 11 & 12
    \end{array} \right]_{4 \times 3}
\end{eqnarray}
$$

**Horizontal stacking `np.hstack`**

$$
\begin{eqnarray}
    \left[ \begin{array}{ccc}
        1 & 2 & 3 \\
        4 & 5 & 6
    \end{array} \right]_{2 \times 3}
    \oplus_1
    \left[ \begin{array}{ccc}
        7 & 8 & 9 \\
        10 & 11 & 12
    \end{array} \right]_{2 \times 3}
    & = &
    \left[ \begin{array}{ccc}
        1 & 2 & 3 & 7 & 8 & 9 \\
        4 & 5 & 6 & 10 & 11 & 12
    \end{array} \right]_{2 \times 6}
\end{eqnarray}
$$

- The operator $\oplus_k$ is concatenation of matrices on axis $k$. `np.vstack` is equivalent to $\oplus_0$, and `np.hstack`, $\oplus_1$.
"""

mat_a = np.array([ [1, 2, 3],
                   [4, 5, 6] ])

mat_b = np.array([ [ 7,  8,  9],
                   [10, 11, 12] ])

mat_c = np.array([ [13, 14, 15],
                   [16, 17, 18],
                   [19, 20, 21],
                   [22, 23, 24] ])

print(f'hstack(A, B) =\n{ np.hstack((mat_a, mat_b)) }\n')
print(f'vstack(A, C) =\n{ np.vstack((mat_a, mat_c)) }\n')

print(f'hstack = concatenate(A, B) on axis 1 (row)\n{ np.concatenate((mat_a, mat_b), axis=1) }\n')
print(f'vstack = concatenate(A, C) on axis 0 (column)\n{ np.concatenate((mat_a, mat_c), axis=0) }\n')

"""### Matrix Norm

- We can compute the size of a matrix $\left\| \mathbf{A} \right\|$ by the command `la.norm`.
- The command computes Frobenius norm, where:
$$
\begin{eqnarray}
    \left\| \mathbf{A} \right\| & = & \mathrm{Frobenius}(\mathbf{A}) \\
    & = & \sqrt{ \sum_{i = 1}^M \sum_{j = 1}^N a_{ij}^2 } \\
    & = & \sqrt{ a_{11}^2 + a_{12}^2 + a_{13}^2 + \ldots + a_{MN}^2 }
\end{eqnarray}
$$
"""

mat6 = np.array( [ [1, 2, 3],
                   [4, 5, 6] ] )

matnorm = la.norm(mat6)
print(matnorm)

"""- We can also compute the norm by projection on a particular axis by specifying the argument `axis`."""

vec_norms_0 = la.norm(mat6, axis=0)
vec_norms_1 = la.norm(mat6, axis=1)
print(vec_norms_0)
print(vec_norms_1)

"""-----
## Exercises 2

### Question 2.1

Construct the following matrices.

$$
\begin{eqnarray}
    \mathbf{A} & = &
    \left[ \begin{array}{cc}
        1 & 2 \\
        3 & 4
    \end{array} \right] \\
    \mathbf{B} & = &
    \left[ \begin{array}{cc}
        5 & 6 \\
        7 & 8
    \end{array} \right] \\
    \mathbf{C} & = &
    \left[ \begin{array}{cccc}
        9 & 10 & 11 & 12 \\
        13 & 14 & 15 & 16
    \end{array} \right] 
\end{eqnarray}
$$
"""

# mat_a = __________
# mat_b = __________
# mat_c = __________
# 
# print(f'A =\n{mat_a}\n')
# print(f'B =\n{mat_b}\n')
# print(f'C =\n{mat_c}\n')

"""#### Solution"""

mat_a = np.array([ [1, 2],
                   [3, 4] ])
mat_b = np.array([ [5, 6],
                   [7, 8] ])
mat_c = np.array([ [ 9, 10, 11, 12],
                   [13, 14, 15, 16] ])

print(f'A =\n{mat_a}\n')
print(f'B =\n{mat_b}\n')
print(f'C =\n{mat_c}\n')

"""### Question 2.2

Concatenate the matrices created in Question 2.1 to construct the following matrices. Feel free to use `np.hstack`, `np.vstack`, and `np.concatenate`.

$$
\begin{eqnarray}
    \mathbf{D} & = &
    \left[ \begin{array}{cccc}
        1 & 2 & 5 & 6 \\
        3 & 4 & 7 & 8
    \end{array} \right] \\
    \mathbf{E} & = &
    \left[ \begin{array}{cc}
        1 & 2 \\
        3 & 4 \\
        5 & 6 \\
        7 & 8
    \end{array} \right] \\
    \mathbf{F} & = &
    \left[ \begin{array}{cccc}
        1 & 2 & 5 & 6 \\
        3 & 4 & 7 & 8 \\
        9 & 10 & 11 & 12 \\
        13 & 14 & 15 & 16
    \end{array} \right] 
\end{eqnarray}
$$
"""

# mat_d = __________
# mat_e = __________
# mat_f = __________
# 
# print(f'D =\n{mat_d}\n')
# print(f'E =\n{mat_e}\n')
# print(f'F =\n{mat_f}\n')

"""#### Solution"""

mat_d = np.hstack([mat_a, mat_b])
mat_e = np.vstack([mat_a, mat_b])
mat_f = np.vstack([mat_d, mat_c])

print(f'D =\n{mat_d}\n')
print(f'E =\n{mat_e}\n')
print(f'F =\n{mat_f}\n')

"""-----
## 3. Matrix Computation

- In NumPy, vectors and matrices are treated similarly.
- Therefore, we can apply mathematical operations such as addition and multiplication on vectors and matrices, given that they have identical shapes.
- Let me define two matrices for our short demonstration.
"""

m1 = np.array( [ [1, 2, 3],
                 [4, 5, 6] ] )
m2 = np.array( [ [ 7,  8,  9],
                 [10, 11, 12] ] )
print(f'm1 =\n{m1}')
print(f'm2 =\n{m2}')

"""### Addition and Subtraction

- We use `+` and `-`, respectively.

$$
\begin{eqnarray}
\left[ \begin{array}{ccc}
    1 & 2 & 3 \\
    4 & 5 & 6
\end{array} \right] + \left[ \begin{array}{ccc}
    7 & 8 & 9 \\
    10 & 11 & 12
\end{array} \right] & = & \left[ \begin{array}{ccc}
    8 & 10 & 12 \\
    14 & 16 & 18
\end{array} \right]
\end{eqnarray}
$$
"""

m_add = m1 + m2
print(f'm1 + m2 =\n{m_add}')

"""$$
\begin{eqnarray}
\left[ \begin{array}{ccc}
    7 & 8 & 9 \\
    10 & 11 & 12
\end{array} \right] - \left[ \begin{array}{ccc}
    1 & 2 & 3 \\
    4 & 5 & 6
\end{array} \right] & = & \left[ \begin{array}{ccc}
    6 & 6 & 6 \\
    6 & 6 & 6
\end{array} \right]
\end{eqnarray}
$$
"""

m_sub = m2 - m1
print(f'm2 - m1 =\n{m_sub}')

"""### Transpose

- We use the property `T` to transpose a matrix.

$$
\begin{eqnarray}
\left[ \begin{array}{ccc}
    1 & 2 & 3 \\
    4 & 5 & 6
\end{array} \right]^\top & = & \left[ \begin{array}{cc}
    1 & 4 \\
    2 & 5 \\
    3 & 6
\end{array} \right]
\end{eqnarray}
$$
"""

m_trans = m1.T
print(f'transpose(m1) =\n{m_trans}')

"""### Scalar Multiplication

- We simply use the operator `*`.

$$
\begin{eqnarray}
4 \times \left[ \begin{array}{ccc}
    1 & 2 & 3 \\
    4 & 5 & 6
\end{array} \right] & = & \left[ \begin{array}{ccc}
    4 & 8 & 12 \\
    16 & 20 & 24
\end{array} \right]
\end{eqnarray}
$$
"""

m_smult = 4 * m1
print(f'4 × m1 =\n{m_smult}')

"""### Matrix Multiplication

- We use the operator `@`.
- Do *NOT* use the operator `*` as it is for element-wise multiplication.

$$
\begin{eqnarray}
\left[ \begin{array}{ccc}
    1 & 2 & 3 \\
    4 & 5 & 6
\end{array} \right]_{2 \times 3} \times \left[ \begin{array}{cc}
    7 & 10 \\
    8 & 11 \\
    9 & 12
\end{array} \right]_{3 \times 2} & = & \left[ \begin{array}{cc}
    50 & 68 \\
    122 & 167
\end{array} \right]_{2 \times 2}
\end{eqnarray}
$$
"""

m_mult = m1 @ m2.T
print(f'm1 × transpose(m2) =\n{m_mult}')

"""- Note that multiplication of `m1` and `m2` would not work due to dimension mismatch.
$$
\left[ \begin{array}{ccc}
    1 & 2 & 3 \\
    4 & 5 & 6
\end{array} \right]_{2 \times 3} \times \left[ \begin{array}{ccc}
    7 & 8 & 9 \\
    10 & 11 & 12
\end{array} \right]_{2 \times 3}
$$
"""

# print(m1 @ m2)       # This will cause an error message.

"""### Element-wise Multiplication

- We use the operator `*` for element-wise multiplication.
$$
\begin{eqnarray}
\left[ \begin{array}{ccc}
    1 & 2 & 3 \\
    4 & 5 & 6
\end{array} \right]_{2 \times 3} \otimes \left[ \begin{array}{ccc}
    7 & 8 & 9 \\
    10 & 11 & 12
\end{array} \right]_{2 \times 3} & = & \left[ \begin{array}{ccc}
    7 & 16 & 27 \\
    40 & 55 & 72
\end{array} \right]_{2 \times 3}
\end{eqnarray}
$$
"""

m_emult = m1 * m2
print(f'm1 * m2 =\n{m_emult}')

"""### Vector-wise Operations via Broadcasting

- For a binary operator e.g. `+`, `-`, `*` and `/`, if one operand is a matrix and the other one is a vector, the vector will be mapped to each row of the matrix before applying that operator element-wise. This procedure is called *broadcasting*.
- For example,
$$
\begin{eqnarray}
    \left[ \begin{array}{ccc}
        1 & 3 & 2 \\
        2 & 2 & 1 \\
        3 & 1 & 3
    \end{array} \right]
    *
    \left[ \begin{array}{ccc}
        4 & 5 & 10
    \end{array} \right]
    & = &
    \left[ \begin{array}{ccc}
        4 & 15 & 20 \\
        8 & 10 & 10 \\
        12 & 5 & 30
    \end{array} \right]
\end{eqnarray}
$$
"""

vec_a = np.array([ [1,3,2],
                   [2,2,1],
                   [3,1,3] ])
vec_b = np.array([4, 5, 10])

print(vec_a * vec_b)

"""- For example,
$$
\begin{eqnarray}
    \left[ \begin{array}{ccc}
        1 & 3 & 2 \\
        2 & 2 & 1 \\
        3 & 1 & 3
    \end{array} \right]
    /
    \left[ \begin{array}{ccc}
        4 & 5 & 10
    \end{array} \right]
    & = &
    \left[ \begin{array}{ccc}
        0.25 & 0.6 & 0.2 \\
        0.5 & 0.4 & 0.1 \\
        0.75 & 0.2 & 0.3
    \end{array} \right]
\end{eqnarray}
$$
"""

vec_a = np.array([ [1,3,2],
                   [2,2,1],
                   [3,1,3] ])
vec_b = np.array([4, 5, 10])

print(vec_a / vec_b)

"""-----
## Exercises 3

### Question 3.1

Define the following matrices and compute $\mathbf{A} + \mathbf{B} + 4 \mathbf{C}$, where

$$
\begin{eqnarray}
    \mathbf{A} & = & \left[ \begin{array}{ccc}
        0 & 0 & 0 \\
        0 & 0 & 0
    \end{array} \right] \\
    \mathbf{B} & = & \left[ \begin{array}{ccc}
        1 & 1 & 1 \\
        1 & 1 & 1
    \end{array} \right] \\
    \mathbf{C} & = & \left[ \begin{array}{ccc}
        1 & 0 & 0 \\
        0 & 1 & 0
    \end{array} \right] \\
\end{eqnarray}
$$
"""

# mat_a = np.zeros( _____ )        # Fill in these blanks
# mat_b = np.ones( _____ )
# mat_c = np.eye( _____ )
# result = __________
# print(result)

"""#### Solution"""

mat_a = np.zeros((2, 3))
mat_b = np.ones((2, 3))
mat_c = np.eye(2, 3)
result = mat_a + mat_b + 4 * mat_c
print(result)

"""### Question 3.2

Compute $\mathbf{A}^\top \times \mathbf{A}$, where $\mathbf{A}$ is a randomized matrix of shape $(3, 4)$.
"""

# mat_a = np.random.randn( _____ )        # Fill in these blanks
# result = __________
# print(result)

"""#### Solution"""

mat_a = np.random.randn(3, 4)        # Fill in these blanks
result = mat_a.T @ mat_a
print(result)

"""### Question 3.3

Compute $ \left( \mathbf{A} \otimes \mathbf{B} \right)^\top \times \mathbf{C}^\top $, where $\mathbf{A}$, $\mathbf{B}$, and $\mathbf{C}$ are randomized matrices of shapes (2, 3), (2, 3), and (3, 2), respectively.
"""

# mat_a = np.random.randn( _____ )        # Fill in these blanks
# mat_b = np.random.randn( _____ )
# mat_c = np.random.randn( _____ )
# result = __________
# print(result)

"""#### Solution"""

mat_a = np.random.randn(2, 3)
mat_b = np.random.randn(2, 3)
mat_c = np.random.randn(3, 2)
result = (mat_a * mat_b).T @ mat_c.T
print(result)

"""### Question 3.4

Compute $ \mathbf{R} = \mathbf{A}^\top \times \mathbf{A} $, where $\mathbf{A}$ is a randomized matrix of shape (3, 4). Then replace the first column with a random vector.
"""

# mat_a = rnd.randn( _____ )
# mat_r = __________
# print(mat_r)
# 
# mat_r[ _____ ] = __________
# print(mat_r)

"""#### Solution"""

mat_a = rnd.randn(3, 4)
mat_r = mat_a.T @ mat_a
print(mat_r)

mat_r[:, 0] = rnd.randn(4)
print(mat_r)

"""### Question 3.5

Construct matrix $\mathbf{F}$, where
$$
\begin{eqnarray}
\mathbf{F} & = &
    \left[ \begin{array}{cccc}
        1 & 2 & 3 & 4 \\
        5 & 6 & 7 & 8 \\
        9 & 10 & 11 & 12 \\
        13 & 14 & 15 & 16
    \end{array} \right] 
\end{eqnarray}
$$
Then convert each *column* of $\mathbf{F}$ into a unit vector using vector-wise operation.
"""

# mat_f = __________
# vec_norms = __________
# 
# result = __________
# 
# print(result)

"""#### Solution"""

mat_f = np.array([ [ 1,  2,  3,  4],
                   [ 5,  6,  7,  8],
                   [ 9, 10, 11, 12],
                   [13, 14, 15, 16] ])
vec_norms = la.norm(mat_f, axis=0)

result = mat_f / vec_norms

print(result)

"""### Question 3.6

Check if each column vector of $\mathbf{F}$ is a unit vector. The norm of a unit vector should be equal or very close to 1. In this question, we say that two real numbers $r_1$ and $r_2$ are very close to each other if $\left| r_1 - r_2 \right| < \epsilon$, where $\epsilon$ is a very small real number e.g. $10^{-6}$.
"""

# for col in range( __________ ):
#     if not __________ :
#         print(f'Column {col} is not a unit vector!')

"""#### Solution"""

for col in range(result.shape[0]):
    if not (abs(la.norm(result[:, col]) - 1.0) <= 1e-6):
        print(f'Column {col} is not a unit vector!')

"""-----
## 4. Tensors

### Tensor as Data Batches

- Tensor is essentially an $N$-dimensional array. It is a generalized form of data collection, where its dimension can be greater than 2.
- In mathematics, we call $N$ the rank of the tensor, and we say that this is a *rank-$N$ tensor*.
- Therefore, any scalar quantity is a rank-0 tensor, any vector is a rank-1 tensor, while any matrix is a rank-2 tensor.
- For the sake of analogy, we can consider any tensor of rank greater than two as a collection of matrices, a.k.a. *batches*.

- For example, we can create a rank-3 tensor $\mathbf{A} = \left[ \begin{array}{c}
    \mathbf{A}_1 \\
    \mathbf{A}_2 
\end{array} \right]$, where $A_1$ and $A_2$ are two batches of data:
$$
\begin{eqnarray}
    \mathbf{A}_1 & = &
    \left[ \begin{array}{cc}
        1 & 2 \\
        3 & 4
    \end{array} \right] \\
    \mathbf{A}_2 & = &
    \left[ \begin{array}{cc}
        5 & 6 \\
        7 & 8
    \end{array} \right]
\end{eqnarray}
$$

- Note that `numpy` separates $\mathbf{A}_1$ and $\mathbf{A}_2$ with a blank line when printed out.
"""

# tsr_a is a 3-dimensional tensor consisting of two matrices
tsr_a = np.array([ [ [1, 2],           # matrix 1
                     [3, 4] ],
                   [ [5, 6],           # matrix 2
                     [7, 8] ] ])
print(tsr_a)

"""- The above tensor can also be rewritten as follows:
$$
\begin{eqnarray}
    \mathbf{A} & = &
    \left[ \begin{array}{c}
        \left[ \begin{array}{cc}
            1 & 2 \\
            3 & 4
        \end{array} \right]
        \\
        \left[ \begin{array}{cc}
            5 & 6 \\
            7 & 8
        \end{array} \right]
    \end{array} \right]
\end{eqnarray}
$$
whose shape is `(2, 2, 2)`.
"""

print(tsr_a.shape)

"""- In the case where rank $N > 3$, more than one blank line is used to separate between dimensions.
- For example, in rank-4 tensor $\mathbf{B}$, the two blank lines separate the first dimension, while each blank line separate the second dimension.

$$
\begin{eqnarray}
    \mathbf{B} & = &
    \left[ \begin{array}{cc}
        \left[ \begin{array}{cc}
            1 & 2 \\
            3 & 4
        \end{array} \right]
        &
        \left[ \begin{array}{cc}
            5 & 6 \\
            7 & 8
        \end{array} \right] \\
        \left[ \begin{array}{cc}
            9 & 10 \\
            11 & 12
        \end{array} \right]
        &
        \left[ \begin{array}{cc}
            13 & 14 \\
            15 & 16
        \end{array} \right]
    \end{array} \right]
\end{eqnarray}
$$
"""

tsr_b = np.array([ [ [ [1, 2],
                       [3, 4] ],
                     [ [5, 6],
                       [7, 8] ] ],
                   [ [ [9, 10],
                       [11, 12] ],
                     [ [13, 14],
                       [15, 16] ] ] ])
print(tsr_b)

"""### Indexing and Setting

- We can do indexing and setting on a tensor simply by `[]` and `:` as if we are dealing with vectors and matrices. 
- For example, let's consider tensor $\mathbf{B}$.

$$
\begin{eqnarray}
    \mathbf{B} & = &
    \left[ \begin{array}{cc}
        \left[ \begin{array}{cc}
            1 & 2 \\
            3 & 4
        \end{array} \right]
        &
        \left[ \begin{array}{cc}
            5 & 6 \\
            7 & 8
        \end{array} \right] \\
        \left[ \begin{array}{cc}
            9 & 10 \\
            11 & 12
        \end{array} \right]
        &
        \left[ \begin{array}{cc}
            13 & 14 \\
            15 & 16
        \end{array} \right]
    \end{array} \right]
\end{eqnarray}
$$
"""

tsr_b = np.array([ [ [ [1, 2],
                       [3, 4] ],
                     [ [5, 6],
                       [7, 8] ] ],
                   [ [ [9, 10],
                       [11, 12] ],
                     [ [13, 14],
                       [15, 16] ] ] ])
print(f'Tensor B:\n{tsr_b}')
print(f'Shape of B = {tsr_b.shape}')

"""- How can we get access to the cell in which 7 is in? The number 7 is in the matrix in row 1, column 2; therefore, we want to address $\mathbf{B}_{1, 2}$. Then, we further address the cell of 7, which is in row 2, column 1.
- Therefore, we obtain that:
$$
\begin{eqnarray}
    B_{1, 2, 2, 1} & = & 7
\end{eqnarray}
$$
"""

print(f'B[0,1,1,0] = { tsr_b[0, 1, 1, 0] }')        # row 1, column 2, row 2, column 1

"""- By placing `:` in a specific dimension, we can now get access to a specified row or column."""

print(f'B[0,1,1,:] = { tsr_b[0, 1, 1, :] }')        # row 1, column 2, row 2, all columns
print(f'B[0,1,:,0] = { tsr_b[0, 1, :, 0] }')        # row 1, column 2, all rows, column 1
print(f'B[0,:,1,0] = { tsr_b[0, :, 1, 0] }')        # row 1, all columns, row 2, column 1
print(f'B[:,1,1,0] = { tsr_b[:, 1, 1, 0] }')        # all rows, column 2, row 2, column 1

"""- Of course, we can place `:` on more than one dimension, resulting in access to a matrix or even a tensor."""

print(f'B[0,1,:,:] =\n{ tsr_b[0, 1, :, :] }\n')        # row 1, column 2, all rows, all columns
print(f'B[0,:,:,0] =\n{ tsr_b[0, :, :, 0] }\n')        # row 1, all columns, all rows, column 1
print(f'B[:,:,1,0] =\n{ tsr_b[:, :, 1, 0] }')          # all rows, all columns, row 2, column 1

print(f'B[0,:,:,:] =\n{ tsr_b[0, :, :, :] }\n')        # row 1, all columns, all rows, all columns
print(f'B[:,1,:,:] =\n{ tsr_b[:, 1, :, :] }\n')        # all rows, column 2, all rows, all columns
print(f'B[:,:,1,:] =\n{ tsr_b[:, :, 1, :] }\n')        # all rows, all columns, row 2, all columns
print(f'B[:,:,:,0] =\n{ tsr_b[:, :, :, 0] }')          # all rows, all columns, all rows, column 1

"""- **Tips for advanced programmers:** If we fix one or both ends of the index sequence, we can replace consecutive `:`'s with `...`"""

print(f'B[0,...] =\n{   tsr_b[0, ...]    }\n')      # equals to tsr_b[0, :, :, :]
print(f'B[:,1,...] =\n{ tsr_b[:, 1, ...] }\n')      # equals to tsr_b[:, 1, :, :]
print(f'B[...,1,:] =\n{ tsr_b[..., 1, :] }\n')      # equals to tsr_b[:, :, 1, :]
print(f'B[...,0] =\n{   tsr_b[..., 0]    }\n')      # equals to tsr_b[:, :, :, 0]
print(f'B[0,...,0] =\n{ tsr_b[0, ..., 0] }')        # equals to tsr_b[0, :, :, 0]

"""- We can also get access to an inner array by simple indexing.
- For example, we can access $\mathbf{B}_{1,2}$ by `tsr_b[0, 1]`.
"""

print(tsr_b[0, 1])

"""### Tensor Stacking

- We can still use the command `np.concatenate` to stack up tensors on a specified axis.

$$
\begin{eqnarray}
    \left[ \begin{array}{c}
        \left[ \begin{array}{cc}
            1 & 2 \\
            3 & 4
        \end{array} \right] \\
        \left[ \begin{array}{cc}
            5 & 6 \\
            7 & 8
        \end{array} \right]
    \end{array} \right]
    \oplus_0
    \left[ \begin{array}{c}
        \left[ \begin{array}{cc}
            9 & 10 \\
            11 & 12
        \end{array} \right] \\
        \left[ \begin{array}{cc}
            13 & 14 \\
            15 & 16
        \end{array} \right]
    \end{array} \right]
    & = &
    \left[ \begin{array}{c}
        \left[ \begin{array}{cc}
            1 & 2 \\
            3 & 4
        \end{array} \right] \\
        \left[ \begin{array}{cc}
            5 & 6 \\
            7 & 8
        \end{array} \right] \\
        \left[ \begin{array}{cc}
            9 & 10 \\
            11 & 12
        \end{array} \right] \\
        \left[ \begin{array}{cc}
            13 & 14 \\
            15 & 16
        \end{array} \right]
    \end{array} \right] \\
    \left[ \begin{array}{c}
        \left[ \begin{array}{cc}
            1 & 2 \\
            3 & 4
        \end{array} \right] \\
        \left[ \begin{array}{cc}
            5 & 6 \\
            7 & 8
        \end{array} \right]
    \end{array} \right]
    \oplus_1
    \left[ \begin{array}{c}
        \left[ \begin{array}{cc}
            9 & 10 \\
            11 & 12
        \end{array} \right] \\
        \left[ \begin{array}{cc}
            13 & 14 \\
            15 & 16
        \end{array} \right]
    \end{array} \right]
    & = &
    \left[ \begin{array}{c}
        \left[ \begin{array}{cc}
            1 & 2 \\
            3 & 4 \\
            9 & 10 \\
            11 & 12
        \end{array} \right] \\
        \left[ \begin{array}{cc}
            5 & 6 \\
            7 & 8 \\
            13 & 14 \\
            15 & 16
        \end{array} \right]
    \end{array} \right] \\
    \left[ \begin{array}{c}
        \left[ \begin{array}{cc}
            1 & 2 \\
            3 & 4
        \end{array} \right] \\
        \left[ \begin{array}{cc}
            5 & 6 \\
            7 & 8
        \end{array} \right]
    \end{array} \right]
    \oplus_2
    \left[ \begin{array}{c}
        \left[ \begin{array}{cc}
            9 & 10 \\
            11 & 12
        \end{array} \right] \\
        \left[ \begin{array}{cc}
            13 & 14 \\
            15 & 16
        \end{array} \right]
    \end{array} \right]
    & = &
    \left[ \begin{array}{c}
        \left[ \begin{array}{cc}
            1 & 2 & 9 & 10 \\
            3 & 4 & 11 & 12
        \end{array} \right] \\
        \left[ \begin{array}{cc}
            5 & 6 & 13 & 14 \\
            7 & 8 & 15 & 16
        \end{array} \right]
    \end{array} \right]
\end{eqnarray}
$$
"""

tsr_1 = np.array([ [ [1, 2],
                     [3, 4] ],
                   [ [5, 6],
                     [7, 8] ] ])

tsr_2 = np.array([ [ [ 9, 10],
                     [11, 12] ],
                   [ [13, 14],
                     [15, 16] ] ])

print(f'concatenate(A, B) on axis 0 =\n{np.concatenate((tsr_1, tsr_2), axis=0)}\n')
print(f'concatenate(A, B) on axis 1 =\n{np.concatenate((tsr_1, tsr_2), axis=1)}\n')
print(f'concatenate(A, B) on axis 2 =\n{np.concatenate((tsr_1, tsr_2), axis=2)}\n')

"""### Tensor Norm

- We can compute the norm of a tensor by the command `la.norm`.
"""

tsr_a = np.array([ [ [1, 2],
                     [3, 4] ],
                   [ [5, 6],
                     [7, 8] ] ])
print(f'Matrix A =\n{tsr_a}\n')
print(f'Norm = {la.norm(tsr_b)}')

"""- We can also compute the norm by projection on a particular axis by specifying the argument `axis`."""

print(f'Matrix A =\n{tsr_a}\n')

print(f'norm on axis 0 =\n{la.norm(tsr_a, axis=0)}')
print(f'norm on axis 1 =\n{la.norm(tsr_a, axis=1)}')
print(f'norm on axis 2 =\n{la.norm(tsr_a, axis=2)}')

"""### Addition and Subtraction

- We use `+` and `-`, respectively.
"""

tsr_a = np.array([ [ [1, 2],
                     [3, 4] ],
                   [ [5, 6],
                     [7, 8] ] ])

tsr_b = np.array([ [ [9, 10],
                     [11, 12] ],
                   [ [13, 14],
                     [15, 16] ] ])

print(f'A + B =\n{tsr_a + tsr_b}\n')
print(f'B - A =\n{tsr_b + tsr_a}')

"""### Scalar Multiplication

- We use the operator `*`.
"""

print(f'4 * A =\n{4 * tsr_a}')

"""### Transpose

- The transpose of a tensor is the reverse of the dimensions of such tensor.
- For example, let's consider a rank-3 tensor $\mathbf{A}$, whose each element is addressed by $A_{ijk}$.
- The transpose of $ \mathbf{A} $, denoted by $\mathbf{A}^\top$, is defined as follows.
$$
\begin{eqnarray}
    \left[ \mathbf{A}^\top \right]_{kji} & = & A_{ijk}
\end{eqnarray}
$$
"""

print(f'A =\n{tsr_a}\n')

print(f'transpose(A) =\n{tsr_a.T}')

# For example, transpose(A)[0, 0, 1] = A[1, 0, 0] = 5

"""- We can also permute the order of dimensions by the method `transpose`. 
- For example, we can permute the dimension order from (0, 1, 2) to (1, 0, 2) by `transpose((1, 0, 2))`
"""

print(f'transpose(A, (1, 0, 2)) =\n{tsr_a.transpose((1, 0, 2))}')

# For example, tranpose(A, (1, 0, 2))[11, 12, 13] = A[12, 11, 13]

"""### Tensor Operations via Broadcasting

- An operation of two tensors is based on broadcasting, where any tensor of size greater than two dimensions is treated as a collection of data batches.
- There are two cases of broadcasting in tensors.

- <font color=blue>**Case 1:**</font> Tensor $\mathbf{A} = \left( 
    \mathbf{A}_1, \mathbf{A}_2, \mathbf{A}_3, \ldots, \mathbf{A}_n
\right)$, when applied on matrix $\mathbf{M}$, is equal to broadcasting such operation of $\mathbf{M}$ to each batch $\mathbf{A}_k$ in $\mathbf{A}$. That is:
$$
\begin{eqnarray}
\mathbf{A} \circ \mathbf{M} & = & \left(
    \mathbf{A}_1 \circ \mathbf{M}, \mathbf{A}_2  \circ \mathbf{M}, \mathbf{A}_3  \circ \mathbf{M}, \ldots, \mathbf{A}_n \circ \mathbf{M}
\right)
\end{eqnarray}
$$
where $\circ$ is a binary operation.
"""

tsr_a = np.array([ [ [ [1, 2],
                       [3, 4] ],
                     [ [5, 6],
                       [7, 8] ] ],
                   [ [ [9, 10],
                       [11, 12] ],
                     [ [13, 14],
                       [15, 16] ] ] ])

tsr_b = np.array([ [0, 1],
                   [1, 0] ])

tsr_a @ tsr_b

"""- <font color=blue>**Case 2:**</font> Tensor $\mathbf{A} = \left( \mathbf{A}_1, \mathbf{A}_2, \mathbf{A}_3, \ldots, \mathbf{A}_n \right)$, when applied on tensor $\mathbf{B} = \left( \mathbf{B}_1, \mathbf{B}_2, \mathbf{B}_3, \ldots, \mathbf{B}_n \right)$, is equal to broadcasting such operation of each corresponding batch pair $\mathbf{A}_k \times \mathbf{B}_k$. That is:
$$
\begin{eqnarray}
\mathbf{A} \circ \mathbf{B} & = & \left(
    \mathbf{A}_1 \circ \mathbf{B}_2, \mathbf{A}_2 \circ \mathbf{B}_2, \mathbf{A}_3 \circ \mathbf{B}_3, \ldots, \mathbf{A}_n \circ \mathbf{B}_n
\right)
\end{eqnarray}
$$
where $\circ$ is a binary operation.
"""

# There are two batches in A, divided by the first dimension
tsr_a = np.array([ [ [ [1, 2],
                       [3, 4] ],
                     [ [5, 6],
                       [7, 8] ] ],
                   [ [ [9, 10],
                       [11, 12] ],
                     [ [13, 14],
                       [15, 16] ] ] ])

# There are also two batches in B
tsr_b = np.array([ [ [1, 0],
                     [0, 1] ],
                   [ [0, 1],
                     [1, 0] ] ])

tsr_a @ tsr_b

"""- **N.B.** Note that two tensors of difference batch sizes cannot be multiplied due to shape mismatch."""

# There are two batches in A
tsr_a = np.array([ [ [1, 2],
                     [3, 4] ],
                   [ [5, 6],
                     [7, 8] ] ])

# There are three batches in B
tsr_b = np.array([ [ [1, 0],
                     [0, 1] ],
                   [ [1, 0],
                     [0, 1] ],
                   [ [0, 1],
                     [1, 0] ] ])

# Running this will cause an exception
# tsr_a @ tsr_b

"""-----
## Exercises 4

### Question 4.1

Let's create a rank-5 tensor $\mathbf{C}$ containing the numbers starting from 1 to 32. Observe how `numpy` prints it out. How many blank lines are used to separate each dimension?
"""

# tsr_c = np.zeros((2, 2, 2, 2, 2))          # Rank-5 tensor
# 
# for i1 in range(2):
#     for i2 in range(2):
#         for i3 in range(2):
#             for i4 in range(2):
#                 for i5 in range(2):
#                     tsr_c[i1, i2, i3, i4, i5] = __________
# 
# print(tsr_c)

"""#### Solution"""

tsr_c = np.zeros((2, 2, 2, 2, 2))          # Rank-5 tensor

for i1 in range(2):
    for i2 in range(2):
        for i3 in range(2):
            for i4 in range(2):
                for i5 in range(2):
                    tsr_c[i1, i2, i3, i4, i5] = \
                        16 * i1 + 8 * i2 + 4 * i3 + 2 * i4 + i5 + 1

print(tsr_c)

"""### Question 4.2

Write down a matrix representation of tensor $\mathbf{C}$ on a sheet of paper. Observe how batches of matrices are organized.

#### Solution

$$
\left[ \begin{array}{cc}
    \left[ \begin{array}{cc}
        \left[ \begin{array}{cc}
            1 & 2 \\
            3 & 4
        \end{array}\right]
        &
        \left[ \begin{array}{cc}
            5 & 6 \\
            7 & 8
        \end{array}\right]
        \\
        \left[ \begin{array}{cc}
            9 & 10 \\
            11 & 12
        \end{array}\right]
        &
        \left[ \begin{array}{cc}
            13 & 14 \\
            15 & 16
        \end{array}\right]
    \end{array} \right]
    \\
    \left[ \begin{array}{cc}
        \left[ \begin{array}{cc}
            17 & 18 \\
            19 & 20
        \end{array}\right]
        &
        \left[ \begin{array}{cc}
            21 & 22 \\
            23 & 24
        \end{array}\right]
        \\
        \left[ \begin{array}{cc}
            25 & 26 \\
            27 & 28
        \end{array}\right]
        &
        \left[ \begin{array}{cc}
            29 & 30 \\
            31 & 32
        \end{array}\right]
    \end{array} \right]
\end{array} \right]
$$

### Question 4.3

**Power Method** is an algorithm that computes the dominant eigenvector (the eigenvector whose eigenvalue is the largest) of a square matrix. The basic idea of the Power Method is quite simple. For a given square matrix $\mathbf{M}$:

  1. Let $\mathbf{v}^{(0)}$ be an arbitrary unit vector.
  2. For each $k$-th iteration
    1. We multiply $\mathbf{M}$ by an unit vector $\mathbf{v}^{(k)}$ to obtain a new vector $\mathbf{v}^{(k + 1)}$.
    2. We normalize $\mathbf{v}^{(k + 1)}$.
  3. We repeat the loop in Step 2 until $\mathbf{v}^{(k + 1)}$ becomes convergent.
  4. The resulted vector becomes the dominant eigenvector of $\mathbf{M}$.

In this exercise, we will implement the Power Method with NumPy step by step.

### Question 4.3.1

Implement a function that normalizes an input vector. It should return a unit vector as a result.
$$
\begin{eqnarray}
    \mathrm{normalize}(\mathbf{v}) & = & \frac{\mathbf{v}}{\left\| \mathbf{v} \right\|}
\end{eqnarray}
$$
"""

# def normalize(vec):
#     return ___________          # Fill in this blank.

"""#### Solution"""

def normalize(vec):
    return vec / la.norm(vec)

"""### Question 4.3.2

Implement a function that checks whether two <u>unit</u> vectors converge or not. In this exercise, vectors $\mathbf{v}_1$ and $\mathbf{v}_2$ are said to converge to each other if their Euclidean distance is less than the given threshold.
$$
\begin{eqnarray}
    \mathrm{dist}(\mathbf{v}_1, \mathbf{v}_2) & = & \left\| \mathbf{v}_1 - \mathbf{v}_2 \right\|
\end{eqnarray}
$$
This function should return a boolean value indicating if $\mathbf{v}_1$ and $\mathbf{v}_2$ converge to each other or not.
"""

# def is_converge(vec1, vec2, threshold):
#     
#     # Compute the Euclidean distance between vec1 and vec2.
#     dist = __________
#     
#     # Return the boolean value that indicates the convergence with respect to the given threshold.
#     return __________

"""#### Solution"""

def is_converge(vec1, vec2, threshold):
    
    # Compute the Euclidean distance between vec1 and vec2.
    dist = la.norm(vec1 - vec2)
    
    # Return the boolean value that indicates the convergence with respect to the given threshold.
    return dist < threshold

"""### Question 4.3.3

Implement a function that computes the dominant eigenvector of a given square matrix $\mathbf{M}$. Read the instruction in the comments carefully and follow it accordingly.
"""

# def power_method(matrix, threshold, maxiters):
#     
#     # Find the first dimension of the given matrix.
#     dim = __________
#     
#     # Randomize an arbitrary unit vector using rnd.randn. This is your v^(0).
#     # Don't forget to normalize it before use.
#     vec = __________
#     
#     # Iterative Power Method
#     for i in range(maxiters):
#         
#         # Multiply the given matrix with vec and normalize the result.
#         newvec = __________
#         
#         # If the obtained vector and the old vector converge, stop the iteration.
#         if is_converge(vec, newvec, threshold):
#             break
#             
#         # Otherwise, keep the obtained vector and continue the iteration.
#         else:
#             vec = newvec
#             
#     return newvec

"""#### Solution"""

def power_method(matrix, threshold, maxiters):
    
    # Find the first dimension of the given matrix.
    dim = matrix.shape[0]
    
    # Randomize an arbitrary unit vector using rnd.randn. This is your v^(0).
    # Don't forget to normalize it before use.
    vec = normalize(rnd.randn(dim))
    
    # Iterative Power Method
    for i in range(maxiters):
        
        # Multiply the given matrix with vec and normalize the result.
        newvec = normalize(matrix @ vec)
        
        # If the obtained vector and the old vector converge, stop the iteration.
        if is_converge(vec, newvec, threshold):
            break
            
        # Otherwise, keep the obtained vector and continue the iteration.
        else:
            vec = newvec
            
    return newvec

"""### Question 4.3.4

Implement a function that computes an eigenvalue $\lambda$ of an eigenvector $\mathbf{v}$ with respect to an input matrix $\mathbf{M}$. The eigenvalue can be computed with the Rayleigh quotient below.
$$
\begin{eqnarray}
    \lambda & = & \frac{\mathbf{v}^\top \mathbf{M} \mathbf{v}}{\mathbf{v}^\top \mathbf{v}}
\end{eqnarray}
$$
"""

# def rayleigh(matrix, vec):
#     return __________

"""#### Solution"""

def rayleigh(matrix, vec):
    return (vec.T @ matrix @ vec) / (vec.T @ vec)

"""### Question 4.3.5

**Testing:** You can test your implementation with the following simple code.
"""

# m = np.array([ [ 1,  2,  3,  4],
#                [ 5,  6,  7,  8],
#                [ 9, 10, 11, 12],
#                [13, 14, 15, 16] ])
# 
# result = power_method(m, 1e-3, 100)
# 
# print(f'Eigenvector = {result}')
# print(f'Eigenvalue  = {rayleigh(m, result)}')

"""#### Solution"""

m = np.array([ [ 1,  2,  3,  4],
               [ 5,  6,  7,  8],
               [ 9, 10, 11, 12],
               [13, 14, 15, 16] ])

result = power_method(m, 1e-3, 100)

print(f'Eigenvector = {result}')
print(f'Eigenvalue  = {rayleigh(m, result)}')

"""-----
## 5. Custom Array Construction

- Instead of keying in all numbers when creating a new array, there are several useful functions that create an array of your desire.

### `np.arange(a, b, step)`

- Create a vector starting from `a` to `b` with the stepping size `step`.
- This command is similar to `range` used in the for-loop. 
- For example, `np.arange(1, 10, 1)` creates an array $[1, 2, 3, \ldots, 9]$.
"""

np.arange(1, 10, 1)

"""- We can determine the step size by changing the last argument.

- For example, `np.arange(1, 10, 2)` creates an array $[1, 3, 5, 7, 9]$.
"""

np.arange(1, 10, 2)

"""- If we set the step size to a negative value, the series will go descendingly.

- For example, `np.arange(10, 0, -1)` creates an array $[10, 9, 8, \ldots, 1]$.
"""

np.arange(10, 0, -1)

"""### `np.linspace(a, b, num)`

- Create a vector starting from `a` to `b` with the specified number of elements `num` (including the start and the end).
- `linspace` is short for 'linear space'.
- For example, `np.linspace(1, 10, 7)` creates an array $[1, 2.5, 4, 5.5, 7, 8.5, 10]$.
"""

np.linspace(1, 10, 7)

"""### Array Reshaping

- Once you create an array, you can reshape it to become a matrix or a tensor with the method `reshape`. 
- For example, we can reshape the array $[1, 2, 3, \ldots, 9]$ to become a matrix of shape (3, 3):

$$
\left[ \begin{array}{ccc}
    1 & 2 & 3 \\
    4 & 5 & 6 \\
    7 & 8 & 9 
\end{array} \right]
$$
"""

vec9 = np.arange(1, 10, 1)
print(f'As a vector:\n{vec9}\n')
mat9 = vec9.reshape(3, 3)
print(f'As a matrix:\n{mat9}')

"""### Array Flattening

- We can flatten a tensor by the command `np.ravel`.
"""

mat9.ravel()

"""### Side Effects of Element Setting in Array Reshaping

- Note that array reshaping does not copy the content of the array.
- We can therefore reshape an array efficiently at any point.
- However, bear in mind that array manipulation has a side effect on any reshaping, too.
- In the below example, changing a cell in any reshape will affect the original content and any of its reshapes, too.
"""

print('BEFORE\n')
vec16 = np.arange(1, 17, 1)
print(f'As a vector:\n{vec16}\n')
mat16 = vec16.reshape(4, 4)
print(f'As a matrix:\n{mat16}\n')
tsr242 = mat16.reshape(2, 4, 2)
print(f'As a (2,4,2)-tensor:\n{tsr242}\n')
tsr2222 = tsr242.reshape(2, 2, 2, 2)
print(f'As a (2,2,2,2)-tensor:\n{tsr2222}\n')

tsr2222[0, 1, 1, 0] = 100

print('AFTER\n')
print(f'As a vector:\n{vec16}\n')
print(f'As a matrix:\n{mat16}\n')
print(f'As a (2,4,2)-tensor:\n{tsr242}\n')
print(f'As a (2,2,2,2)-tensor:\n{tsr2222}\n')

"""### `np.fromfunction(fn, shape)`

- Create a tensor of the specified shape `shape` using the specified function `fn`.
"""

def fn(x, y):
    return (x * y + 1) / (x + y + 1)

# The below command is equivalent to the following code.
# mat_d = np.zeros((5, 3))
# for i in range(5):
#     for j in range(3):
#         mat_d[i, j] = fn(i, j)
mat_d = np.fromfunction(fn, (5, 3))
print(mat_d)

"""-----
## Exercises 5

### Question 5.1

**The Cube of Numbers:** Receive an integer $n$ from the user and create a 3-dimensional tensor containing the numbers starting from 1 to $n^3$. The one-liner way to solve this problem is to use `np.arange` and `reshape`. For example, 

```
    Enter n: 3
    [[[ 1  2  3]
      [ 4  5  6]
      [ 7  8  9]]

     [[10 11 12]
      [13 14 15]
      [16 17 18]]

     [[19 20 21]
      [22 23 24]
      [25 26 27]]]
```
"""

# # Receive an integer from the user.
# n = int(input('Enter n: '))
# 
# # Construct a 3-D tensor containing 1 to n**3.
# tensor = __________       # Fill in this blank.
# 
# # Print it out.
# print(tensor)

"""#### Solution"""

# Receive an integer from the user.
n = 10     # Please change it to `input` in the answer box.

# Construct a 3-D tensor containing 1 to n**3.
tensor = 1 + np.arange(n ** 3).reshape(n, n, n)

# Print it out.
print(tensor)

"""### Question 5.2

Suppose you want plot a line chart representing a growth trend of virus colonies against the number of days in the incubation period. Create two vectors for the X and Y axes, where:
  - The X axis shows the number of days, ranging from 0 to 20 (days), and increasing 1 at a time.
  - The Y axis shows the total area of virus colonies in the cultured dish, ranging from 0 to 50.0 (cm squared), and containing 8 steps.
"""

# x_axis = __________          # Fill in these blanks.
# y_axis = __________
# 
# print(f'X axis:\n{x_axis}\n')
# print(f'Y axis:\n{y_axis}\n')

"""#### Solution"""

x_axis = np.arange(0, 21, 1)
y_axis = np.linspace(0, 50.0, 8)

print(f'X axis:\n{x_axis}\n')
print(f'Y axis:\n{y_axis}\n')

"""-----
## 6. Boolean Operations on Array

### First Order Logic

- We can apply boolean operations on any array, resulting in an array of truth values of the same shape, called *condition*.
"""

mat_a = rnd.randn(5, 3)
print(f'Matrix A =\n{mat_a}\n')

cond_1 = (mat_a >= 0.25)
print(f'Condition = (A >= 0.25)\n{cond_1}\n')

"""- We can also add bit-wise logical connectives `&` (and), `|` (or), `^` (exclusive or), and `~` (not) in a logical expression containing arrays. 
- Do not use the traditional logical connectives `and`, `or`, and `not` as they will cause errors.
- Note that we always use parentheses each operand of these connectives. 
"""

# Note that you cannot use Python's chained syntax -0.25 <= mat_a <= 0.25.
cond_2 = (mat_a >= -0.25) & (mat_a <= 0.25)
print(f'Condition = (-0.25 <= A <= 0.25)\n{cond_2}\n')

"""- We can count the number of elements that satisfy the logical expression via the command `np.sum`. The command counts `True` as 1 and `False` as 0, respectively."""

np.sum(cond_2)

"""- Logical quantifiers such as `np.any` (for some) and `np.all` (for all) can also be applied to the boolean operations to obtain a final truth value."""

print(f'Any element of A is in [-0.25, 0.25] = {np.any(cond_2)}')
print(f'All element of A is in [-0.25, 0.25] = {np.all(cond_2)}')

"""- You can also specify the projection axis of `np.any` and `np.all` with the argument `axis`."""

print(f'Any element of A is in [-0.25, 0.25] = {np.any(cond_2, axis=0)}')
print(f'All element of A is in [-0.25, 0.25] = {np.all(cond_2, axis=1)}')

"""### Boolean Masking

- We can extract the elements whose truth values are `True` by simple indexing.
"""

mat_a = rnd.randn(5, 3)
print(f'Matrix A =\n{mat_a}\n')

cond_1 = (-0.25 <= mat_a) & (mat_a <= 0.25)
print(f'Condition = (-0.25 <= A <= 0.25)\n{cond_1}\n')

print(f'Masking A with Condition =\n{mat_a[cond_1]}')

"""- We can also set the elements whose truth values are `True` by indexing."""

mat_a[cond_1] = 0.0
print(mat_a)

"""### Conditional Array Creation

- We can create a new array out of two input arrays according to a given condition with the command `np.where`.
- Note that both input arrays must have the same shape.
"""

mat_a = rnd.randn(5, 3)
print(f'Matrix A =\n{mat_a}\n')

cond_1 = (-0.25 <= mat_a) & (mat_a <= 0.25)
print(f'Condition = (-0.25 <= A <= 0.25)\n{cond_1}\n')

mat_c = rnd.randint(1, 10, (5, 3))
print(f'Matrix C =\n{mat_a}\n')

mat_d = rnd.randint(11, 20, (5, 3))
print(f'Matrix D =\n{mat_b}\n')

# For each element of cond_1:
#     If that element of cond_1 is True, choose the corresponding element from C
#     Otherwise, choose the corresponding element from D instead
result = np.where(cond_1, mat_c, mat_d)
print(f'Result = where(Condition, C, D)\n{result}')

"""-----
## Exercises 6

In this exercise, we are going to observe some behaviors of *pseudo-randomization*. That is, we are wondering if we can find any patterns in these random numbers. One way to do so is we will generate a sequence of some random numbers and observe its accumulated positivity through the sequence.

For example, suppose we have a sequence of random numbers:

$$
[0.1, -0.75, 0.9, 1.7, -0.9, -2.5, 0.05, 0.7, 1.9, -2.1, -0.3, -0.1]
$$

At first glance, we do not see any patterns in these random numbers.

To unveil the pattern, we observe the positive accumulator. For each number in the sequence, we increase the posive accumulator by 1 if it is a positive number, and decrease the accumulator by 1 if it is a negative number. If we observe the change in the accumulator, we can now see the following pattern.

$$
[1, 0, 1, 2, 1, 0, 1, 2, 3, 2, 1, 0]
$$

### Question 6.1

Implement this process in the following code.
"""

# # Number of random numbers
# no_nums = 400
# 
# # Generate a random vector a of dimension [no_nums].
# vec_a = __________
# 
# # Create a zero vector of dimension [no_nums].
# result = __________
# 
# # Accumulator
# acc = 0.0
# for i in range(no_nums):
#     # If each element in vector a is greater or equal to 0, then increase the accumulator.
#     if __________ :
#         acc += 1
#     # Otherwise, decreate the accumulator.
#     else:
#         acc -= 1
#     # Save the value of the accumulator to result.
#     result[i] = acc
#     
# print(f'Result:\n{result}\n')
# 
# # Count the number of zeros in the result.
# print(f'Number of zeros = { __________ }')

"""#### Solution"""

# Number of random numbers
no_nums = 400

# Generate a random vector a of dimension [no_nums].
vec_a = rnd.randn(no_nums)

# Create a zero vector of dimension [no_nums].
result = np.zeros(no_nums)

# Accumulator
acc = 0.0
for i in range(no_nums):
    # If each element in vector a is greater or equal to 0, then increase the accumulator.
    if vec_a[i] >= 0:
        acc += 1
    # Otherwise, decreate the accumulator.
    else:
        acc -= 1
    # Save the value of the accumulator to result.
    result[i] = acc
    
print(f'Result:\n{result}\n')

# Count the number of zeros in the result.
print(f'Number of zeros = { (result == 0).sum() }')

"""### Question 6.2

Try different numbers of random numbers `no_nums` and observe the patterns.

### Question 6.3

What does the number of zeros tell us about the patterns?

-----
## 7. Useful Functions on Array

### Summation

- We can compute the summation of all elements in an array by the command `np.sum()`.
- If the argument `axis` is determined, the summation will be computed on such axis; i.e. the summation is projected on that axis.
"""

mat_a = np.array([ [ 1,  2,  3,  4,  5],
                   [ 6,  7,  8,  9, 10],
                   [11, 12, 13, 14, 15] ])

print(f'Matrix A =\n{mat_a}\n')

sum_all = np.sum(mat_a)
print(f'Summation of all elements = {sum_all}')

sum_0 = np.sum(mat_a, axis=0)
print(f'Summation on axis 0 (row) = {sum_0}')

sum_1 = np.sum(mat_a, axis=1)
print(f'Summation on axis 1 (column) = {sum_1}')

"""### Aggregation

- We can compute aggregation functions, e.g. `np.max`, `np.min`, `np.average`, `np.median`, `np.argmax`, and `np.argmin`, on an array as well.
- If the argument `axis` is determined, the computation will be projected on such axis.
"""

mat_a = np.array([ [ 1,  2,  3,  4,  5],
                   [10,  9,  8,  7,  6],
                   [11, 12, 13, 14, 15] ])

print(f'Matrix A =\n{mat_a}\n')

max_elem = np.max(mat_a)
min_elem = np.min(mat_a)
print(f'Maximum element = {max_elem}')
print(f'Minimum element = {min_elem}\n')

avg_elem = np.average(mat_a)
avg_1 = np.average(mat_a, axis=0)
avg_2 = np.average(mat_a, axis=1)
print(f'Average = {avg_elem}')
print(f'Average on axis 0 (row) = {avg_1}')
print(f'Average on axis 1 (column) = {avg_2}\n')

med_elem = np.median(mat_a)
med_1 = np.median(mat_a, axis=0)
med_2 = np.median(mat_a, axis=1)
print(f'Median = {med_elem}')
print(f'Median on axis 0 (row) = {med_1}')
print(f'Median on axis 1 (column) = {med_2}\n')

# argmax and argmin return the maximum and minimum indices, respectively
argmax_1 = np.argmax(mat_a, axis=0)
argmin_2 = np.argmin(mat_a, axis=1)
print(f'Argmax on axis 0 (row) = {argmax_1}')
print(f'Argmin on axis 1 (column) = {argmin_2}')

"""### Cumulative Summation

- We can compute the cumulative summation on each index by the command `np.cumsum`. 
- The argument `axis` is also available for axis projection.
"""

mat_b = np.array([ [ 0,  1,  2,  3],
                   [ 4,  5,  6,  7],
                   [ 8,  9, 10, 11],
                   [12, 13, 14, 15],
                   [16, 17, 18, 19],
                   [20, 21, 22, 23] ])
print(f'Matrix B:\n{mat_b}\n')

cumsum_1 = np.cumsum(mat_b, axis=0)
cumsum_2 = np.cumsum(mat_b, axis=1)
print(f'Cumulative summation on axis 0 (row) =\n{cumsum_1}\n')
print(f'Cumulative summation on axis 1 (column) =\n{cumsum_2}')

"""### Sampling

- We can draw some samples from an item collection based on a probability distribution of each item with the command `rnd.choice(collection, size, p)`. 
- The argument `p` is a uniform distribution by default.
"""

words    = ['hello', 'world', 'prachya', 'boonkwan']
probdist = [   0.15,    0.30,      0.25,       0.30]

samples_uniform = rnd.choice(words, 5)
print(f'5 samples from a uniform distribution: {samples_uniform}')

samples_word = rnd.choice(words, 5, p=probdist)
print(f'5 samples from a predefined distribution: {samples_word}')

"""-----
## Exercises 7

The value of $\pi$ was discovered for more than 3,500 years. The constant $\pi$, as the Babylonians and the Egyptians understood, is the ratio between a circle's diameter and its circumference. In the ancient Greek time, mathematician Archimedes of Syracuse (287-212 BC) is widely accepted to be the first to compute the value of $\pi$. He did not calculate its exact value. However, he approximated its close value by inscribing a circle between a $n-1$ polygon and another $n$ polygon and compute the upper and lower bounds of the value of $\pi$.

In this exercise, we will approximate the value of $\pi$ via simple simulation. Imagine we have a circle inscribed in a square.

<center>![A circle inscribed in a square](https://www.varsitytutors.com/assets/vt-hotmath-legacy/hotmath_help/topics/circles-inscribed-in-squares/lesson1.gif)</center>

Suppose the circle's radius is $r$, the area of the circle is $\pi r^2$, while the area of the inscribing square is $(2r)^2 = 4 r^2$. We obtain that

$$
\begin{eqnarray}
    \frac{\textrm{Area of circle}}{\textrm{Area of square}} & = & \frac{\pi r^2}{4 r^2} \\
    \therefore \quad \pi & = & 4 \times \frac{\textrm{Area of circle}}{\textrm{Area of square}}
\end{eqnarray}
$$

Now we have come to the question of approximating the area of a circle. We can do so with simulation. The probability of a random point being inside the circle given that the point is already inside the square is:

$$
\begin{eqnarray}
    P(\textrm{inside circle} | \textrm{inside square}) & \approx & \frac{P(\textrm{inside circle}, \textrm{inside square})}{P(\textrm{inside square})} \\
    & = & \frac{\#(\textrm{inside circle}, \textrm{inside square})}{\#(\textrm{inside square})}
\end{eqnarray}
$$

where $\#$ is the frequency of random points of such condition.

By combining the results of above derivation, we obtain that:

$$
\begin{eqnarray}
    \pi & = & 4 \times \frac{\textrm{Area of circle}}{\textrm{Area of square}} \\
    & \approx & 4 \times  \frac{\#(\textrm{inside circle}, \textrm{inside square})}{\#(\textrm{inside square})}
\end{eqnarray}
$$

We will approximate the value of $\pi$ via this simulation method.

### Question 7.1

Implement a function that checks if each row vector in the input matrix $\mathbf{M}$ is in a circle with the radius of $r$. We say that a vector $\mathbf{v}$ is in that circle if the vector's norm $\left\| \mathbf{v} \right\| \leq r$.
"""

# def is_in_circle(vecs, radius):
#
#     # Find the norm of each row vector.
#     rownorms = __________
#
#     # Create a criterion for each row vector being in the circle of a specified radius.
#     criterion = __________
#
#     return criterion

"""#### Solution"""

def is_in_circle(vecs, radius):
    
    # Find the norm of each row vector.
    rownorms = la.norm(vecs, axis=1)
    
    # Create a criterion for each row vector being in the circle of a specified radius.
    criterion = rownorms <= radius
    
    return criterion

"""### Question 7.2

Implement the following simulation method for the value of $\pi$.

  1. Suppose there is a circle whose diameter is 2 and it is inscribed in a square whose side is of length 2.

  2. Draw $N$ random points from a uniform distribution in the range of [-1, 1]
  
  3. Count the number of random points that are in the circle. Let's denote that number with $C$.
  
  4. Approximate the value of $\pi \approx \frac{C}{N}$.
"""

# # Let's set the number of random points.
# num_points = 100
# 
# # Random [num_points] random points of two dimensions.
# vecs = __________
# 
# # Check if each random point is in such circle using [is_in_circle].
# in_circle = __________
# 
# # Count the random points that are in the circle.
# count_in = __________
# 
# # Approximate the value of pi.
# pi_value = 4 * count_in / num_points
# 
# print(pi_value)

"""#### Solution"""

# Let's set the number of random points.
num_points = 100000

# Random [num_points] random points of two dimensions.
vecs = rnd.uniform(-1, 1, (num_points, 2))

# Check if each random point is in such circle.
in_circle = is_in_circle(vecs, 1)

# Count the random points that are in the circle.
count_in = in_circle.sum()

# Approximate the value of pi.
pi_value = 4 * count_in / num_points

print(pi_value)

"""-----
## 8. Sparse Matrices

- Furthermore, there are two types of matrices in NumPy: dense and sparse.
  - For the dense matrix, its entire content is stored as an array in the memory.
  - For the sparse matrix, only some parts of its content are stored in the memory to save some space.
- The latter type offers some space efficiency but may underperform in some mathematical operations and content manipulation.

- There are four popular sparse formats:
  1. Coordinate format (COO)
  2. Compressed sparse row (CSR)
  3. Compressed sparse column (CSC)
  4. Block sparse row (BSR)

### Coordinate Format (COO)

- In this format, the content is stored as a list of triplets ((row, column), element).
- This format is easiest to construct, especially for a very large matrix. We just have to know the shape of the matrix.
- Once the COO matrix is constructed, it is usually converted to CSR, CSC, or BSR for efficient computation.

- We can construct a COO matrix with the command `sp.coo_matrix` as follows. Note that all elements in repeated coordinates are accumulated.
"""

rows = rnd.randint(0, 10, size=8)
cols = rnd.randint(0, 5, size=8)
data = rnd.randn(8)
print(f'Rows = {rows}')
print(f'Cols = {cols}')
print(f'Data = {data}\n')

coo_a = sp.coo_matrix((data, (rows, cols)), shape=(10, 5))
print(f'COO Matrix A:\n{coo_a}\n')

mat_a = coo_a.toarray()                 # Convert to a dense matrix
print(f'Dense Matrix A:\n{mat_a}')

"""### Sparse Formats (CSR, CSC, and BSR)

- Once we have constructed the COO matrix, we then convert it to either the CSR, CSC, or BSR format for faster computation, such as arithmetic operations, slicing, and decomposition.

  - CSR matrix is suitable for row slicing and large matrix multiplication.

  - CSC matrix is suitable for column slicing and large matrix multiplication.

  - BSR matrix is suitable for dense sub-matrices.

- The CSR and CSC formats are more space-efficient than the BSR format, but the latter is more speed-efficient in arithmetic operations.
- In most cases, CSR and CSC are adequate for large matrix multiplication, while BSR is suitable for any computation related to dense sub-matrices such as finite element discretization.
"""

csr_a = coo_a.tocsr()
print(f'CSR Matrix A:\n{csr_a}')

csc_a = coo_a.tocsc()
print(f'CSC Matrix A:\n{csc_a}')

bsr_a = coo_a.tobsr()
print(f'BSR Matrix A:\n{bsr_a}')

"""Of course, arithmetic operations can be applied to these formats."""

bsr_mult = bsr_a.T @ bsr_a

print(f'transpose(A) x A =\n{bsr_mult}\n')

print(f'Dense =\n{bsr_mult.toarray()}')

"""-----
## Exercises 8

In Question 4.3, we have implemented the Power Method that computes the dominant eigenvector of any square matrix. The disadvantages of this algorithm are that it converges slowly and the convergence is rather unstable when the input matrix becomes very large and sparse (containing many zeros). In this exercise, we will implement an improvement version of the Power Method called **PageRank** (Brin and Page, 1998).

PageRank offers a more stable way to compute the dominant eigenvector of a very large matrix. The *damping factor* $\delta$ is introduced to the Power Method to stabilize the convergence. When the input matrix $\mathbf{M}$ is multiplied by the vector $\mathbf{v}^{(k)}$, we weight the resultant vector with $\delta$, smooth it with a constant $1 - \delta$, and normalize the result. Doing so will stabilize the convergence because of the smoothing process.

An overview of the algorithm is as follows. For a given square matrix $\mathbf{M}$:

  1. Let $\mathbf{v}^{(0)}$ be an arbitrary unit vector.
  2. For each $k$-th iteration
    1. We multiply $\mathbf{M}$ by an unit vector $\mathbf{v}^{(k)}$ to obtain a new vector $\mathbf{v}'$.
    2. We set $\mathbf{v}^{(k + 1)} = \delta \mathbf{v}' + (1-\delta) \mathbf{1}$, where $\mathbf{1}$ is a one vector. This step is called **smoothing**.
    3. Normalize $\mathbf{v}^{(k + 1)}$.
  3. We repeat the loop in Step 2 until $\mathbf{v}^{(k + 1)}$ becomes convergent.
  4. The resulted vector becomes the dominant eigenvector of $\mathbf{M}$.

In this exercise, we will implement PageRank using sparse matrices, simple matrix operations, and aggregation functions. We will also evaluate the speed of this implementation with a large sparse matrix.

### Question 8.1

Implement a function that normalizes an input vector. It should return a unit vector as a result.
$$
\begin{eqnarray}
    \mathrm{normalize}(\mathbf{v}) & = & \frac{\mathbf{v}}{\left\| \mathbf{v} \right\|}
\end{eqnarray}
$$
"""

# def normalize(vec):
#     return ___________          # Fill in this blank.

"""#### Solution"""

def normalize(vec):
    return vec / la.norm(vec)

"""### Question 8.2

Implement a function that checks whether two <u>unit</u> vectors converge or not. In this exercise, vectors $\mathbf{v}_1$ and $\mathbf{v}_2$ are said to converge to each other if their Euclidean distance is less than the given threshold.
$$
\begin{eqnarray}
    \mathrm{dist}(\mathbf{v}_1, \mathbf{v}_2) & = & \left\| \mathbf{v}_1 - \mathbf{v}_2 \right\|\
\end{eqnarray}
$$
This function should return a boolean value indicating if $\mathbf{v}_1$ and $\mathbf{v}_2$ converge to each other or not.
"""

# def is_converge(vec1, vec2, threshold):
#     
#     # Compute the Euclidean distance between vec1 and vec2.
#     dist = __________
#     
#     # Return the boolean value that indicates the convergence with respect to the given threshold.
#     return __________

"""#### Solution"""

def is_converge(vec1, vec2, threshold):
    
    # Compute the Euclidean distance between vec1 and vec2.
    dist = la.norm(vec1 - vec2)
    
    # Return the boolean value that indicates the convergence with respect to the given threshold.
    return dist <= threshold

"""### Question 8.3

Implement a function that computes the dominant eigenvector of a given square matrix $\mathbf{M}$. Read the instruction in the comments carefully and follow it accordingly.
"""

# def pagerank(matrix, threshold, maxiters, dampfact):
#     
#     # Find the first dimension of the given matrix.
#     dim = __________
#     
#     # Randomize an arbitrary unit vector using rnd.randn.
#     # Don't forget to normalize it before use.
#     vec = __________
#     
#     # Iterative Power Method
#     for i in range(maxiters):
#         
#         # Multiply the given matrix with the vector. Do not normalize it just yet.
#         matrix_vec = __________
#         
#         # Smooth the multiplication result with the damping factor. Also normalize the result of smoothing.
#         newvec = __________
#         
#         # If the obtained vector and the old vector converge, stop the iteration.
#         if is_converge(vec, newvec, threshold):
#             break
#             
#         # Otherwise, keep the obtained vector and continue the iteration.
#         else:
#             vec = newvec
#             
#     return newvec

"""#### Solution"""

def pagerank(matrix, threshold, maxiters, dampfact):
    
    # Find the first dimension of the given matrix.
    dim = matrix.shape[0]
    
    # Randomize an arbitrary unit vector using rnd.randn.
    # Don't forget to normalize it before use.
    vec = rnd.randn(dim)
    
    # Iterative Power Method
    for i in range(maxiters):
        
        # Multiply the given matrix with the vector. Do not normalize it just yet.
        matrix_vec = matrix @ vec
        
        # Smooth the multiplication result with the damping factor. Also normalize the result of smoothing.
        newvec = normalize(dampfact * matrix_vec + (1 - dampfact))
        
        # If the obtained vector and the old vector converge, stop the iteration.
        if is_converge(vec, newvec, threshold):
            break
            
        # Otherwise, keep the obtained vector and continue the iteration.
        else:
            vec = newvec
            
    return newvec

"""### Question 8.4

Implement a function that computes an eigenvalue $\lambda$ of an eigenvector $\mathbf{v}$ with respect to an input matrix $\mathbf{M}$. The eigenvalue can be computed with the Rayleigh quotient below.
$$
\begin{eqnarray}
    \lambda & = & \frac{\mathbf{v}^\top \mathbf{M} \mathbf{v}}{\mathbf{v}^\top \mathbf{v}}
\end{eqnarray}
$$
"""

# def rayleigh(matrix, vec):
#     return __________

"""#### Solution"""

def rayleigh(matrix, vec):
    return (vec.T @ matrix @ vec) / (vec.T @ vec)

"""### Question 8.5

Now let's implement a function that generate a large sparse matrix according to the given numbers of nodes and edges.

For example, we can create a matrix of size 7 whose total number of edges is 5 by calling `make_matrix(7, 5)`.

```python
>>> m = make_matrix(7, 5)
>>> print(m.toarray())
[[0. 0. 0. 0. 1. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0.]]
```
"""

# def make_matrix(no_nodes, no_edges):
#     
#     # Randomize a sequence of row IDs, whose length is equal to no_edges.
#     # Each row ID is in the range [0, no_nodes).
#     rows = __________
#     
#     # Randomize a sequence of column IDs, whose length is equal to no_edges.
#     # Each column ID is in the range [0, no_nodes).
#     cols = __________
#     
#     # This is the frequency count for each edge.
#     data = np.ones(no_edges)
#     
#     # Create a COO sparse matrix out of rows, cols, and data.
#     coo_m = __________
#     
#     # Convert coo_m to a CSR sparse matrix.
#     csr_m = __________
#     
#     return csr_m

"""#### Solution"""

def make_matrix(no_nodes, no_edges):
    
    # Randomize a sequence of row IDs, whose length is equal to no_edges.
    # Each row ID is in the range [0, no_nodes).
    rows = rnd.randint(0, no_nodes, no_edges)
    
    # Randomize a sequence of column IDs, whose length is equal to no_edges.
    # Each column ID is in the range [0, no_nodes).
    cols = rnd.randint(0, no_nodes, no_edges)
    
    # This is the frequency count for each edge.
    data = np.ones(no_edges)
    
    # Create a COO sparse matrix out of rows, cols, and data.
    coo_m = sp.coo_matrix((data, (rows, cols)), shape=(no_nodes, no_nodes))
    
    # Convert coo_m to a CSR sparse matrix.
    csr_m = coo_m.tocsr()
    
    return csr_m

"""### Question 8.6

**Testing:** You can test your implementation with the following simple code.
"""

# m = make_matrix(1000, 20000)
# 
# v = pagerank(m, 1e-3, 20, 0.85)
# print(v)

"""#### Solution"""

m = make_matrix(1000, 20000)

v = pagerank(m, 1e-3, 20, 0.85)
print(v)

"""-----"""